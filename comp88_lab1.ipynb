{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kenkenkenkenny/COMP0088-Introduction-to-Machine-Learning/blob/main/comp88_lab1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# COMP0088 Lab Assignment 1\n",
        "\n"
      ],
      "metadata": {
        "id": "iZgl8O7b-fi9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction\n",
        "\n",
        "This first lab assignment may be considered something of a warm-up exercise. It is an opportunity to get to grips with working in the Colab environment and get acquainted with some basic data generation and plotting. None of the tasks involve any actual **machine learning**, but they do introduce some models and mechanisms that will be extremely important in the weeks ahead.\n",
        "\n",
        "For each task, you are asked to write the code for some functions. The function interface is defined -- please do not change this -- and you are told what it should do. At the end of each task is a code cell that calls the functions and produces some results, usually in the form of plots. Some examples of what the completed plots might look like are shown below. Your outputs do not need to look exactly like these, but they will probably have the same general form. (In future lab assignments the plotting functions will often be provided for you, but in this introductory exercise you are asked to do the plotting yourself and can style it however you like.)\n",
        "\n",
        "![example of completed plots](https://comp0088.github.io/assets/colab/week_1_small.jpg)\n",
        "\n",
        "If you already have experience using NumPy and Matplotlib, especially in the context of ML, you may find some of the exercises trivial. If so, there are suggestions of further things to try in the **Further Exploration** section.\n",
        "\n",
        "Conversely, if you do not have any such experience, the exercises may be a bit daunting. Don't worry if some of the concepts seem strange and unfamiliar at this point. We'll go into linear models at length in week 2, and return to them frequently all the way through the module. For now, just try to understand the basic ideas. If you have problems, feel free to ask the tutors for help.\n",
        "\n",
        "Before we get to the actual tasks there are some subsections below introducing Colab and the notebook format and demonstrating some basic plotting. Feel free to skip over the **Using Colab** and **Basic Plotting** sections if you're already comfortable with those things, but please make sure to run all the code cells in the **Setting Up** section -- these import things that will be needed for the rest of the assignment.\n",
        "\n",
        "There are some potentially helpful utility functions in the `utils` module that gets downloaded and imported in **Setting Up**. You don't have to make use of these, but it is probably worth having a look at them, as they can help avoid some tedious mucking about with things like array axis ordering.\n",
        "\n",
        "**Note:** A couple of this week's exercises can be reduced to one-liners with judicious use of `utils`, but the resulting code is rather cryptic. You'll probably find it helpful to code things in more explicit steps to begin with. (This week's example solutions will do things both ways.)\n"
      ],
      "metadata": {
        "id": "N12ZHil1_ZVN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using Colab"
      ],
      "metadata": {
        "id": "8z6V4BH3_Jra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Google Colaboratory provides free access to computational resources via a web-based front end known as a **notebook**. There are pros and cons to this approach, but it does have the virtue of providing a consistent software environment for everyone without having to wrestle with installation and configuration woes on dozens of different, subtly-incompatible laptops.\n",
        "\n",
        "The notebook content is broken down into **cells**, of which there are two basic types:\n",
        "* **Text** cells (like this one) contain rich text and possibly other media such as images. You should **read** the content of these cells!\n",
        "* **Code** cells (like the one below) contain program instructions in Python, and sometimes other operating system commands. The latter are typically prefixed by an exclamation mark, like this: `!ls -l`\n",
        "   \n",
        "   Code content can be executed on the remote **virtual machine** by clicking on the **play**  ( ▶︎ ) button that appears in the top left hand corner of the cell when you move your cursor over it. Some code may take a while to run — the play button will change to a **stop** (◾️) button, and an animated progress wheel will show around it. As the code runs, it may produce output, which will appear at the bottom of the cell. You can click the stop button to halt the execution.\n",
        "\n",
        "  (The notebook must be **connected** to a virtual machine in order to run code cells. This should happen automatically the first time you attempt to execute a cell — there will be a delay while this takes place.)\n",
        "\n",
        "Try clicking the play button on the cell below to run it."
      ],
      "metadata": {
        "id": "4djncs15HjDT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# a very simple example of a code cell\n",
        "# running the cell will execute the statement below and generate output\n",
        "print('hello world!')"
      ],
      "metadata": {
        "id": "cjQ9mzQiRSzC",
        "outputId": "3f34c1f4-d05a-466f-a499-299f1babb9bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello world!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are two important caveats to be aware of, one to do with the Jupyter notebook interface and the other to do with Colab:\n",
        "\n",
        "1. The notebook interface allows **out of order execution** of code cells. That is, it is possible to run later cells before earlier ones. This is really **never what you want** and can give rise to all kinds of problems with inconsistent state. Always be sure to run cells in order. If you need to go back and re-run earlier cells (eg, because you want to change something) always follow that up by re-running all the subsequent cells in order too, to make sure everything is consistent.\n",
        "\n",
        "2. The virtual machine environment that Colab runs behind this notebook interface is **resource-limited** and **transient**. If you don't do anything for awhile, the notebook may disconnect from the virtual machine. If you use too much computation then your session may be halted — and what qualifies as \"too much\" is kept intentionally vague. VMs are purged daily: if you stop and come back to it tomorrow the VM will have been deleted and you will need to go back to the beginning and go through the setup steps again. If you generate something that you want to keep, you should download it to your local machine.\n"
      ],
      "metadata": {
        "id": "twrVv_VbbIzE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting Up"
      ],
      "metadata": {
        "id": "hxzyJ3xeT4LB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook makes use of the NumPy library for numerical computing and the Matplotlib library for plotting. These are both extremely standard and are installed by default on your Colab instance. We just need to tell the Python interpreter we want to use them:"
      ],
      "metadata": {
        "id": "4vHvSz5pReci"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gL8UJ7lgLznk"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import numpy.random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# this is probably the default, but just in case\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We're also going to bring in some shared COMP0088 lab code from the module GitHub:"
      ],
      "metadata": {
        "id": "K1RLN5QATflG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load lab code and resources\n",
        "!git clone https://github.com/comp0088/shared.git comp0088\n",
        "\n",
        "# at the moment this is all we care about\n",
        "import comp0088.utils as utils"
      ],
      "metadata": {
        "id": "v3X7LDC5KAob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# finally, set up some items for use in later code\n",
        "shared_rng = numpy.random.default_rng()\n",
        "\n",
        "WEIGHTS = np.array([0.5, -0.4, 0.6])\n",
        "LIMITS = (-5, 5)\n",
        "\n",
        "def test_func(X):\n",
        "    \"\"\"\n",
        "    Simple example function of 2 variables for\n",
        "    testing grid & random optimisation.\n",
        "    \"\"\"\n",
        "    return (X[..., 0]-1)**2 + X[...,1]**2 + 2 * np.abs((X[...,0]-1) * X[...,1])"
      ],
      "metadata": {
        "id": "PfZQlfuELVwe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Basic Plotting\n",
        "\n",
        "The [Matplotlib](https://matplotlib.org) library provides extensive plotting capabilities,\n",
        "originally modelled on those in Matlab. The library is big and\n",
        "complicated, and though there is [extensive documentation online](https://matplotlib.org/stable/users/) it can be quite daunting at first.\n",
        "\n",
        "Here we provide a few simple example plots that you can use as\n",
        "starting points for some of the visualisations in the lab\n",
        "assignments. They are not intended to be exhaustive, nor to be\n",
        "perfect exemplars of best practice. If you are already familiar\n",
        "with Matplotlib or just want to dig into it on your own, feel free\n",
        "to ignore these examples.\n",
        "\n",
        "It is pretty common practice, especially in a notebook environment and when doing exploratory data analysis, to use the \"implicit\" `pyplot` API for plotting. This does some behind the scenes object management for you, effectively maintaining global objects representing the current figure and graph axes. This API is slightly more succinct, allowing concise plotting commands like this:"
      ],
      "metadata": {
        "id": "-PUVVe8LAOh4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create some simple data to plot\n",
        "xx = np.linspace(-10,10,100)\n",
        "yy = xx * xx\n",
        "\n",
        "# plot it using the implicit pyplot API\n",
        "plt.plot(xx, yy);"
      ],
      "metadata": {
        "id": "w7HnpVjhdPl7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "However, the downside of this API is that it is less transparent and also less flexible. Here we will instead use the \"explicit\" (also referred to as the \"object oriented\") API, where we create and manage figures and axes ourselves. This is a little bit more verbose, but allows us more control and is a bit more upfront about what is being done."
      ],
      "metadata": {
        "id": "i0F7BsN8dRGv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# explicitly create a figure object and graph axes with in it\n",
        "fig = plt.figure(figsize=(6, 4))\n",
        "ax = fig.subplots()\n",
        "\n",
        "# plot the same data as before using the explicit API\n",
        "ax.plot(xx, yy);"
      ],
      "metadata": {
        "id": "j0OrEq2weUz8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this very simple example there's not a whole lot of difference between the two approaches, but for more complex plots the explicit API is more versatile. For more on the differences between these APIs, see [this documentation page](https://matplotlib.org/stable/users/explain/api_interfaces.html)."
      ],
      "metadata": {
        "id": "5aH5r_e9e31N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Line & Scatter Plots\n",
        "\n",
        "The [`plot`](https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.plot.html) method produces a generic 2D line and/or scatter plot, with graphical details such as colour and marker specified as additional parameters. We can call it multiple times to add additional content to a plot, and can also use further methods on the Axes object to add things like axis labels and a legend, as in the example below.\n",
        "\n",
        "For more complex scatter plots, eg with variable marker size, there is also the [`scatter`](https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.scatter.html) method."
      ],
      "metadata": {
        "id": "29sz50HEN_jx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(6, 6))\n",
        "ax = fig.subplots()\n",
        "\n",
        "# generate a noiseless ideal cubic curve\n",
        "xx = np.linspace(-5, 5, 51)\n",
        "yy = xx * xx * xx\n",
        "\n",
        "ax.plot(xx, yy, color='teal', marker='', linestyle='-', label='Ideal Curve')\n",
        "\n",
        "# generate some noisy sample points\n",
        "xx = shared_rng.random(50) * 10 - 5\n",
        "yy = xx * xx * xx + shared_rng.normal(scale=4, size=50)\n",
        "\n",
        "ax.plot(xx, yy, color='darkorchid', marker='o', linestyle='', label='Noisy Sample', alpha=0.5)\n",
        "\n",
        "# you can use (some) LaTeX formatting in text labels\n",
        "ax.set_xlabel('$x$')\n",
        "ax.set_ylabel('$y = x^3$')\n",
        "\n",
        "ax.set_title('Simple Cubic Function')\n",
        "\n",
        "# add a legend\n",
        "# by default this includes whatever we have provide a label for above\n",
        "ax.legend();\n"
      ],
      "metadata": {
        "id": "bRP6wb9DQs7M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Histograms\n",
        "\n",
        "We'll often want to visualise the *distribution* of data. A very common tool for this is a [histogram](https://en.wikipedia.org/wiki/Histogram), which we can plot using the [`hist`](https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.hist.html) method."
      ],
      "metadata": {
        "id": "dfIs2pJRV_JY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(6, 4))\n",
        "ax = fig.subplots()\n",
        "\n",
        "# generate some univariate Gaussian data\n",
        "xx = shared_rng.normal(size=1000)\n",
        "\n",
        "# plot as a density histogram (ie, area sums to 1)\n",
        "ax.hist(xx, bins=21, density=True, color='cornflowerblue', edgecolor='black')\n",
        "\n",
        "ax.set_xlabel('Sample Value')\n",
        "ax.set_ylabel('Density')\n",
        "ax.set_title('Histogram of N(0,1) samples');"
      ],
      "metadata": {
        "id": "2ApFlWvdWBTq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3D Data\n",
        "\n",
        "We will often have to deal with data with more than two dimensions. Visualising higher dimensional data in general can be very difficult, but for 3D we have some decent options. Two common approaches are to use colour or intensity to represent the third dimension, or to use some form of 3D projection. We will illustrate both approaches below.\n",
        "\n",
        "For simplicity we'll consider data with two **independent variables** $x$ and $y$, and a single **dependent variable** $z$ that is a function of those variables:\n",
        "\n",
        "$$z = f(x, y) = \\cos((x-1)^2 + (y+0.5)^2)$$\n",
        "\n",
        "We can sample many different values of $x$ and $y$ and calculate $z$ for each one. One common sampling strategy uses the NumPy functions [`linspace`](https://numpy.org/doc/stable/reference/generated/numpy.linspace.html) and [`meshgrid`](https://numpy.org/doc/stable/reference/generated/numpy.meshgrid.html) to sample all points on a grid."
      ],
      "metadata": {
        "id": "B_MI6GIuWBwr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.linspace(-2.5, 2.5, 100)\n",
        "y = np.linspace(-1.5, 1.5, 100)\n",
        "\n",
        "xx, yy = np.meshgrid(x, y)\n",
        "zz = np.cos((xx-1)*(xx-1) + (yy+0.5)*(yy+0.5))"
      ],
      "metadata": {
        "id": "yr_tXno4JIaQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using colour to display the value of $z$ at every point on a regular $(x,y)$ grid is exactly equivalent to displaying an **image**, which can be done in Matplotlib using the [`imshow`](https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.imshow.html) method.\n",
        "\n",
        "By default, `imshow` just uses the pixel dimensions of the image for the axis dimension, and it displays the image from the top downwards, which is how images are normally stored. However, in this case we want to specify the **extents** -- the value ranges across and down -- so that they match up with out $(x,y)$ values, and we also want to have the origin at the bottom, because it's standard for graphs to have $y$ increase upwards. So we add some extra options to our `imshow` call.\n",
        "\n",
        "In addition, we're going to add some contour lines -- partly because they help make the gradients a little bit clearer, but mostly for decorative effect."
      ],
      "metadata": {
        "id": "6ckEHa_QKs4Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate the coordinate range and aspect ratio\n",
        "extent = (np.min(xx), np.max(xx), np.min(yy), np.max(yy))\n",
        "aspect = (extent[1] - extent[0])/(extent[3] - extent[2])\n",
        "\n",
        "fig = plt.figure(figsize=(6, 6))\n",
        "ax = fig.subplots()\n",
        "\n",
        "ax.imshow(zz, cmap='cividis', origin='lower', extent=extent, aspect=aspect)\n",
        "\n",
        "# add some contour lines\n",
        "levels = np.linspace(np.min(zz), np.max(zz), 7)\n",
        "ax.contour(xx, yy, zz, levels, cmap='rainbow', origin='lower', extent=extent, alpha=0.5 )\n",
        "\n",
        "ax.set_xlabel('$x$')\n",
        "ax.set_ylabel('$y$')\n",
        "ax.set_title('$z = \\cos((x-1)^2 + (y+0.5)^2)$');\n",
        "\n"
      ],
      "metadata": {
        "id": "9qM5grIfKtmf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alternatively, we can render the data as a **surface** within a projected 3D space, using the [`plot_surface`](https://matplotlib.org/stable/api/_as_gen/mpl_toolkits.mplot3d.axes3d.Axes3D.plot_surface.html) method.\n",
        "\n",
        "(Note that this requires a different kind of Axes object -- [Axes3D](https://matplotlib.org/stable/api/toolkits/mplot3d/axes3d.html) -- which in turn means that rather than the shorthand [`Figure.subplots`](https://matplotlib.org/stable/api/figure_api.html#matplotlib.figure.Figure.subplots) method used previously, we'll instead use the slightly different [`Figure.add_subplot`](https://matplotlib.org/stable/api/figure_api.html#matplotlib.figure.Figure.add_subplot) interface. This is the sort of fiddly detail that can make Matplotlib daunting, but don't worry about it too much. We'll mostly stick to 2D plotting in this module.)"
      ],
      "metadata": {
        "id": "tpt_kYfyNQwp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(6, 6))\n",
        "ax = fig.add_subplot(1, 1, 1, projection='3d')\n",
        "\n",
        "ax.plot_surface( xx, yy, zz, rcount=100, ccount=100, cmap='ocean', antialiased=False, linewidth=0 )\n",
        "ax.set_zlim(-1.2, 1.2)\n",
        "ax.set_xlabel('$x$')\n",
        "ax.set_ylabel('$y$')\n",
        "ax.set_zlabel('$z$')\n",
        "ax.set_title('$z = \\cos((x-1)^2 + (y+0.5)^2)$');"
      ],
      "metadata": {
        "id": "xiIEb06uNRYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 1: Generating linear continuous data\n",
        "\n",
        "A continuous **linear model** is one whose output is just a weighted sum of the input features:\n",
        "\n",
        "$$y = w_0 + w_1 x_1 + w_2 x_2 + ... + w_d x_d = \\sum_{i=0}^d w_i x_i$$\n",
        "\n",
        "where we've defined a constant dummy feature $x_0 = 1$ to capture the intercept term $w_0$ in the sum. We can express this concisely in vector form:\n",
        "\n",
        "$$y = \\mathbf{w \\cdot x \\quad\\quad w},\\mathbf{x} \\in \\mathbb{R}^{d+1}$$\n",
        "\n",
        "This is a *deterministic* model, fully parameterised by the weight vector $\\mathbf{w}$. In practice we might expect there to be some amount of measurement error or other uncertainty in the values we obtain for $y$. One way to represent this uncertainty is with an additive error term, $\\varepsilon$:\n",
        "\n",
        "$$y = \\mathbf{w \\cdot x} + \\varepsilon$$\n",
        "\n",
        "This is not the only way to model the uncertainty, or necessarily the best, but it is nice and simple and very commonly used. In the absence of other information about $\\varepsilon$, we will often further assume that it follows a Gaussian distribution with mean zero (since the location is already modelled by $w_0$) and standard deviation $\\sigma$:\n",
        "\n",
        "$$\\varepsilon \\sim N(0, \\sigma^2)$$\n",
        "\n",
        "Given $\\mathbf{w}$ and $\\sigma$, we can the generate any number of samples $(\\mathbf{x},y)$ from this model by choosing values for $\\mathbf{x}$."
      ],
      "metadata": {
        "id": "FXpzvXtJAr4x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 Generate samples from a linear model with additive Gaussian noise\n",
        "\n",
        "Implement the body of the `generate_noisy_linear` function in the cell below.\n",
        "\n",
        "Note the following:\n",
        "\n",
        "* The function arguments `weights` and `sigma` correspond to $\\mathbf{w}$ and $\\sigma$ in the equations given above.\n",
        "* `weights[0]` is the intercept term $w_0$. Hence, the number of features, $d$, is *one less* than the length of `weights`.\n",
        "* Use the supplied generator `rng` to obtain random numbers. The Generator class is documented [here](https://numpy.org/doc/stable/reference/random/generator.html), but probably the most immediately relevant methods are [random](https://numpy.org/doc/stable/reference/random/generated/numpy.random.Generator.random.html), [uniform](https://numpy.org/doc/stable/reference/random/generated/numpy.random.Generator.uniform.html) and [normal](https://numpy.org/doc/stable/reference/random/generated/numpy.random.Generator.normal.html).\n",
        "\n",
        "**IMPORTANT**: Here and in all subsequent tasks, whenever you make changes to the code you must **run the cell again** to propagate your updates to the runtime environment."
      ],
      "metadata": {
        "id": "RGJxos1yA34M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_noisy_linear(num_samples, weights, sigma, limits, rng):\n",
        "    \"\"\"\n",
        "    Draw samples from a linear model with additive Gaussian noise.\n",
        "\n",
        "    # Arguments\n",
        "        num_samples: number of samples to generate\n",
        "            (ie, the number of rows in the returned X\n",
        "            and the length of the returned y)\n",
        "        weights: vector defining the model\n",
        "            (including a bias term at index 0)\n",
        "        sigma: standard deviation of the additive noise\n",
        "        limits: a tuple (low, high) specifying the value\n",
        "            range of all the input features x_i\n",
        "        rng: an instance of numpy.random.Generator\n",
        "            from which to draw random numbers\n",
        "\n",
        "    # Returns\n",
        "        X: a matrix of sample inputs, where\n",
        "            the samples are the rows and the\n",
        "            features are the columns\n",
        "            ie, its size should be:\n",
        "              num_samples x (len(weights) - 1)\n",
        "        y: a vector of num_samples output values\n",
        "    \"\"\"\n",
        "\n",
        "    # TODO: implement this\n",
        "    return None, None\n"
      ],
      "metadata": {
        "id": "y_sR5c4GnH-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 Plot a 1D linear model\n",
        "\n",
        "Complete the implementation of the `plot_noisy_linear_1d` function below. Note that the function generates the data to plot by calling the function you implemented in part 1.1. You may find it useful to refer to the example in the [Line & Scatter Plots](#scrollTo=29sz50HEN_jx) subsection above."
      ],
      "metadata": {
        "id": "pmEVLSS_A_Iq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_noisy_linear_1d(axes, num_samples, weights, sigma, limits, rng):\n",
        "    \"\"\"\n",
        "    Generate and plot points from a noisy single-feature linear model,\n",
        "    along with a line showing the true (noiseless) relationship.\n",
        "\n",
        "    # Arguments\n",
        "        axes: a Matplotlib Axes object into which to plot\n",
        "        num_samples: number of samples to generate\n",
        "            (ie, the number of rows in the returned X\n",
        "            and the length of the returned y)\n",
        "        weights: vector defining the model\n",
        "            (including a bias term at index 0)\n",
        "        sigma: standard deviation of the additive noise\n",
        "        limits: a tuple (low, high) specifying the value\n",
        "            range of all the input features x_i\n",
        "        rng: an instance of numpy.random.Generator\n",
        "            from which to draw random numbers\n",
        "\n",
        "    # Returns\n",
        "        None\n",
        "    \"\"\"\n",
        "    assert(len(weights)==2)\n",
        "    X, y = generate_noisy_linear(num_samples, weights, sigma, limits, rng)\n",
        "\n",
        "    # TODO: remove the following line and do the plotting\n",
        "    utils.plot_unimplemented ( axes, 'Noisy 1D Linear Model' )"
      ],
      "metadata": {
        "id": "N1HQhBjQE3Tm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3 Plot a 2D linear model\n",
        "\n",
        "Complete the implementation of the `plot_noisy_linear_2d` function below.\n",
        "\n",
        "While this problem is similar to the previous one, note that this model is significantly harder to visualise because there are three dimensions of data to consider: two inputs and one output. To make matters worse, the Axes object you are passed in the first argument is only a 2d Cartesian one, not a 3d projection. So you'll need to consider how to represent it and that may affect what data you need to generate. (The [3D Data](#scrollTo=B_MI6GIuWBwr) example might be helpful here.)"
      ],
      "metadata": {
        "id": "p3gNjIlUBWQF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_noisy_linear_2d(axes, resolution, weights, sigma, limits, rng):\n",
        "    \"\"\"\n",
        "    Produce a plot illustrating a noisy two-feature linear model.\n",
        "\n",
        "    # Arguments\n",
        "        axes: a Matplotlib Axes object into which to plot\n",
        "        resolution: how densely should the model be sampled?\n",
        "        weights: vector defining the model\n",
        "            (including a bias term at index 0)\n",
        "        sigma: standard deviation of the additive noise\n",
        "        limits: a tuple (low, high) specifying the value\n",
        "            range of all the input features x_i\n",
        "        rng: an instance of numpy.random.Generator\n",
        "            from which to draw random numbers\n",
        "\n",
        "    # Returns\n",
        "        None\n",
        "    \"\"\"\n",
        "    assert(len(weights)==3)\n",
        "\n",
        "    # TODO: generate the data\n",
        "    # TODO: remove the following line and do the plotting\n",
        "    utils.plot_unimplemented ( axes, 'Noisy 2D Linear Model' )"
      ],
      "metadata": {
        "id": "YgUq0y6QFC-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## → Run Task 1\n",
        "\n",
        "Execute the code cell below to run the previous tasks and generate a pair of plots.\n",
        "\n",
        "(BTW, if you found yourself wondering earlier why there are separate objects for figure and axes, this might help clarify that.)"
      ],
      "metadata": {
        "id": "NPwNjtpYh_F2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(8, 4))\n",
        "axs = fig.subplots(ncols=2)\n",
        "\n",
        "plot_noisy_linear_1d(axs[0], 50, WEIGHTS[1:], 0.5, LIMITS, shared_rng)\n",
        "plot_noisy_linear_2d(axs[1], 100, WEIGHTS, 0.2, LIMITS, shared_rng)\n",
        "fig.tight_layout(pad=1)"
      ],
      "metadata": {
        "id": "m5XyX-uSFWON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 2: Generating linearly separable binary data\n",
        "\n",
        "We can use an equation akin to the model in Task 1 to define a linear boundary -- or **separating\n",
        "hyperplane** -- that divides a feature space into disjoint half-spaces:\n",
        "\n",
        "$$\\mathbf{w \\cdot x} = 0$$\n",
        "\n",
        "In a **binary classification** problem, if there exists at least one such hyperplane for which all samples of class 0 are on one side and all those of class 1 are on the other, then the data are said to be **linearly separable**, and we can define a classifier using the hyperplane as a decision boundary:\n",
        "\n",
        "\\begin{equation*}\n",
        "y = \\begin{cases}\n",
        "\t1 & \\text{if $\\mathbf{w \\cdot x} \\ge 0$}\\\\\n",
        "\t0 & \\text{otherwise}\n",
        "     \\end{cases}\n",
        "\\end{equation*}\n",
        "\n",
        "Putting aside the question of how to *find* such a plane, or whether it makes a *good* classifier, we can see that (as with the continuous case in Task 1) it is easy to generate samples $(\\mathbf{x}, y)$ given $\\mathbf{w}$.\n",
        "\n"
      ],
      "metadata": {
        "id": "FMWP8eI3Ba46"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 Generate sample data with binary labels that are linearly separable in a continuous feature space\n",
        "\n",
        "Implement the `generate_linearly_separable` function below.\n",
        "\n",
        "(The notes from Task 1.1 also apply here.)"
      ],
      "metadata": {
        "id": "rpZPvjqBBmqF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_linearly_separable(num_samples, weights, limits, rng):\n",
        "    \"\"\"\n",
        "    Draw samples from a binary model with a given linear\n",
        "    decision boundary.\n",
        "\n",
        "    # Arguments\n",
        "        num_samples: number of samples to generate\n",
        "            (ie, the number of rows in the returned X\n",
        "            and the length of the returned y)\n",
        "        weights: vector defining the decision boundary\n",
        "            (including a bias term at index 0)\n",
        "        limits: a tuple (low, high) specifying the value\n",
        "            range of all the input features x_i\n",
        "        rng: an instance of numpy.random.Generator\n",
        "            from which to draw random numbers\n",
        "\n",
        "    # Returns\n",
        "        X: a matrix of sample vectors, where\n",
        "            the samples are the rows and the\n",
        "            features are the columns\n",
        "            ie, its size should be:\n",
        "              num_samples x (len(weights) - 1)\n",
        "        y: a vector of num_samples binary labels\n",
        "    \"\"\"\n",
        "    # TODO: implement this\n",
        "    return None, None"
      ],
      "metadata": {
        "id": "2rTVOKdyLFMB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 Plot a set of labelled 2D samples and their boundary line\n",
        "\n",
        "Complete the implementation of the function `plot_linearly_separable_2d` below. As in 1.2, the call to generate the data using the function above is provided, all you need to do is plot it.\n",
        "\n",
        "Aim to include most or all of the following features in your plot:\n",
        "\n",
        "* All the generated samples, with their class clearly indicated (eg, by colour and shape).\n",
        "* A line marking the decision boundary. You will need to calculate the end points (or other defining parameters such as gradient and intercept) from the weights vector. Consider how to do this -- are there any edge cases you need to take into account.\n",
        "* An [arrow](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.arrow.html) to show the weight vector itself.\n",
        "\n",
        "Verify that the weight vector is normal to the boundary and points towards the positive class."
      ],
      "metadata": {
        "id": "gb13HFsdB1Pc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_linearly_separable_2d(axes, num_samples, weights, limits, rng):\n",
        "    \"\"\"\n",
        "    Plot a linearly separable binary data set in a 2d feature space.\n",
        "\n",
        "    # Arguments\n",
        "        axes: a Matplotlib Axes object into which to plot\n",
        "        num_samples: number of samples to generate\n",
        "            (ie, the number of rows in the returned X\n",
        "            and the length of the returned y)\n",
        "        weights: vector defining the decision boundary\n",
        "            (including a bias term at index 0)\n",
        "        limits: a tuple (low, high) specifying the value\n",
        "            range of all the input features x_i\n",
        "        rng: an instance of numpy.random.Generator\n",
        "            from which to draw random numbers\n",
        "\n",
        "    # Returns\n",
        "        None\n",
        "    \"\"\"\n",
        "    assert(len(weights)==3)\n",
        "    X, y = generate_linearly_separable(num_samples, weights, limits, rng)\n",
        "\n",
        "    # TODO: do the plotting\n",
        "    utils.plot_unimplemented ( axes, 'Linearly Separable Binary Data' )"
      ],
      "metadata": {
        "id": "SEYLZNSzLFok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## → Run Task 2\n",
        "\n",
        "Execute the code cell below to run the function you wrote above and generate a plot."
      ],
      "metadata": {
        "id": "7cOF1Dyfig7Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(6, 6))\n",
        "ax = fig.subplots()\n",
        "\n",
        "plot_linearly_separable_2d(ax, num_samples=100, weights=WEIGHTS, limits=LIMITS, rng=shared_rng)"
      ],
      "metadata": {
        "id": "o-zoeOPlLG15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 3: Searching for the minimiser of a function\n",
        "\n",
        "In Lecture 1.3 we introduced the notation\n",
        "\n",
        "$$\\text{argmin}_x f(x)$$\n",
        "\n",
        "to denote the problem of finding the value of the input $x$ that minimises the output of $f$. In general this problem may be arbitrarily difficult, since $f$ could be anything.\n",
        "\n",
        "The NumPy library includes a function of the same name, [`argmin`](https://numpy.org/doc/stable/reference/generated/numpy.argmin.html), which addresses a much more limited (and tractable) task: it finds the location of the smallest value in an array. Despite its simplicity, this can sometimes be enough to find the exact minimiser (if $x$ can only take on a few discrete values) or at least to find an approximate one by **sampling**.\n",
        "\n",
        "Let $\\mathbf{x}$ be a vector of sampled inputs $[ x_1, x_2, ..., x_n ]$ and $\\mathbf{y}$ the vector of corresponding outputs $[ f(x_1), f(x_2), ..., f(x_n) ]$. If $j = $ `argmin(` $\\mathbf{y}$ `)` (in the NumPy sense), then $x_j$ is (of the available choices) our best estimate of $\\text{argmin}_x f(x)$.\n",
        "\n",
        "There are various possible ways to choose candidate values of $x$, but here we'll look at two common ones: either randomly or at regular intervals."
      ],
      "metadata": {
        "id": "swxeclj-B54s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 Perform a random search for the minimum value of a function\n",
        "\n",
        "Provide an implementation body for the `random_search` function defined in the cell below.\n",
        "\n",
        "Some points to note:\n",
        "\n",
        "* Here (and below, and in future assignments) we make use of the ability to pass one function to another as an argument. To execute the function passed in as the argument `function` on some array `X` you can just call it like any other function:\n",
        "  ```\n",
        "  y = function(X)\n",
        "  ```\n",
        "* The return value should be just a single feature vector: all other samples are discarded."
      ],
      "metadata": {
        "id": "KXLDZUltCAFb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def random_search(function, count, num_samples, limits, rng):\n",
        "    \"\"\"\n",
        "    Randomly sample from a function of `count` features and return\n",
        "    the best feature vector found.\n",
        "\n",
        "    # Arguments\n",
        "        function: a function taking a single input array of\n",
        "            shape (..., count), where the last dimension\n",
        "            indexes the features\n",
        "        count: the number of features expected by the function\n",
        "        num_samples: the number of samples to generate & search\n",
        "        limits: a tuple (low, high) specifying the value\n",
        "            range of all the input features x_i\n",
        "        rng: an instance of numpy.random.Generator\n",
        "            from which to draw random numbers\n",
        "\n",
        "    # Returns\n",
        "        x: a vector of length count, containing the found features\n",
        "    \"\"\"\n",
        "\n",
        "    # TODO: implement this\n",
        "    return None"
      ],
      "metadata": {
        "id": "SA_hr24lNqOz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 Perform a grid search for the minimum value of a function\n",
        "\n",
        "Provide an implementation for the `grid_search` function in the cell below.\n",
        "\n",
        "A common NumPy idiom for grid sampling (inherited from Matlab) employs [`linspace`](https://numpy.org/doc/stable/reference/generated/numpy.linspace.html) and [`meshgrid`](https://numpy.org/doc/stable/reference/generated/numpy.meshgrid.html) to generate evenly spaced values and combine dimensions respectively. An example of this usage can be found in `utils.make_grid`. You may find it more convenient to use this function, since it also conforms the results to our feature indexing convention. (As ever, you don't have to, and solutions will be provided both ways.)\n",
        "\n",
        "How does the computational complexity of `grid_search` scale with the number of features? What does that suggest about its potential applicability?\n"
      ],
      "metadata": {
        "id": "1gcbkYGnCFAF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def grid_search(function, count, num_divisions, limits):\n",
        "    \"\"\"\n",
        "    Perform a grid search for a function of `count` features and\n",
        "    return the best feature vector found.\n",
        "\n",
        "    # Arguments\n",
        "        function: a function taking a single input array of\n",
        "            shape (..., count), where the last dimension\n",
        "            indexes the features\n",
        "        count: the number of features expected by the function\n",
        "        num_divisions: the number of samples along each feature\n",
        "            dimension (including endpoints)\n",
        "        limits: a tuple (low, high) specifying the value\n",
        "            range of all the input features x_i\n",
        "\n",
        "    # Returns\n",
        "        x: a vector of length count, containing the found features\n",
        "    \"\"\"\n",
        "\n",
        "    # TODO: implement this\n",
        "    return None"
      ],
      "metadata": {
        "id": "QU-Q9boENq0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.3. Plot a 2D function along with minimum values found by grid and random searching\n",
        "\n",
        "Provide an implementation for the `plot_searches_2d` function in the cell below.\n",
        "\n",
        "Use the functions defined in the previous sections to perform the grid and random searches.\n",
        "\n",
        "Try to include most or all of the following features:\n",
        "\n",
        "* An **image** (of size `resolution` × `resolution` pixels) showing the output values of the function over its full range in both feature dimensions, with the output value represented by colour. Generating this will require similar steps to those in your grid search, but you will need all the returned function values rather than the minimum feature vector. (You may find the `imshow` example in the [3D Data](#scrollTo=B_MI6GIuWBwr) section helpful here.)\n",
        "* A marker indicating the minimum point found by a random search.\n",
        "* A marker indicating the minimum point found by a grid search.\n",
        "* If `true_min` is provided, a marker showing the real function minimum.\n",
        "\n"
      ],
      "metadata": {
        "id": "THhj6qVZCLte"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_searches_2d(axes, function, limits, resolution,\n",
        "                     num_divisions, num_samples, rng, true_min=None):\n",
        "    \"\"\"\n",
        "    Plot a 2D function aling with minimum values found by\n",
        "    grid and random searching.\n",
        "\n",
        "    # Arguments\n",
        "        axes: a Matplotlib Axes object into which to plot\n",
        "        function: a function taking a single input array of\n",
        "            shape (..., 2), where the last dimension\n",
        "            indexes the features\n",
        "        limits: a tuple (low, high) specifying the value\n",
        "            range of both input features x1 and x2\n",
        "        resolution: number of samples along each side\n",
        "            (including endpoints) for an image representation\n",
        "            of the function\n",
        "        num_divisions: the number of samples along each side\n",
        "            (including endpoints) for a grid search for\n",
        "            the function minimum\n",
        "        num_samples: number of samples to draw for a random\n",
        "            search for the function minimum\n",
        "        rng: an instance of numpy.random.Generator\n",
        "            from which to draw random numbers\n",
        "        true_min: an optional (x1, x2) tuple specifying\n",
        "            the location of the actual function minimum\n",
        "\n",
        "    # Returns\n",
        "        None\n",
        "    \"\"\"\n",
        "\n",
        "    # TODO: implement this\n",
        "    utils.plot_unimplemented ( axes, 'Sampling Search' )"
      ],
      "metadata": {
        "id": "ZFgv6NuGNrYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## → Run Task 3\n",
        "\n",
        "Execute the code cell below to run the function you wrote in the previous cell and produce the plot.\n"
      ],
      "metadata": {
        "id": "7DBIxl_ZitVG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(6, 6))\n",
        "ax = fig.subplots()\n",
        "\n",
        "plot_searches_2d(ax, test_func, limits=LIMITS, resolution=100, num_divisions=10,\n",
        "                 num_samples=100, rng=shared_rng, true_min=(1,0))"
      ],
      "metadata": {
        "id": "T-C7I1zBNr4V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code uses the following function as a test case:\n",
        "\n",
        "\\begin{equation}\n",
        "y = (x_1 - 1)^2 + x_2^2 + \\big| 2 (x_1 - 1) x_2 \\big|\n",
        "\\end{equation}\n",
        "\n",
        "It can be seen by inspection that this function has its minimum at $(1, 0)$, and this value is passed as `true_min`. How does this compare to the values discovered by the grid and random searches? How consistent is that if you re-run the test several times? Looking at the parameters with which the script calls `plot_searches_2d`, how might you estimate the probability that random search outperforms grid search here?\n"
      ],
      "metadata": {
        "id": "9ES2V_v5meb2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Further exploration\n",
        "\n",
        "If you have exhausted the previous exercises, you might find it interesting to try out one or more of the following challenges. Doing so is entirely optional, but may provide some additional perspective that could be useful in the weeks ahead.\n",
        "\n",
        "Note that no code cells or outline code are provided for these, you'll need to do it all yourself. But the `utils` module includes a function `plot_classification_map` (which we'll be using in future weeks) that you may find useful for visualising decision boundaries.\n"
      ],
      "metadata": {
        "id": "ENAVpErdCTaX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot the 2D models from tasks 1.3 and 3.3 in 3D projection\n",
        "\n",
        "For simplicity, in the exercises above we plotted the models above (with 2 input dimensions and 1 output) as flat images, using colour to represent the third dimension. Using a 3D projection can sometimes be more intuitive. Try plotting those models in such a projection.\n",
        "\n",
        "Note that Matplotlib uses a different Axes class for 3D plots, so you will need to specify `projection='3d'` when adding the axes object to your figure. See [3D Data](#scrollTo=B_MI6GIuWBwr) section for an example of this.\n"
      ],
      "metadata": {
        "id": "HqJRn5FmCXNR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Construct decision boundaries by preprocessing the inputs\n",
        "\n",
        "In [Task 2](#scrollTo=FMWP8eI3Ba46), the decision boundary is based on a weighted sum of the raw input vector $\\mathbf{x}$. What would happen if you instead applied some preprocessing function $f: \\mathbb{R}^d \\mapsto \\mathbb{R}^k$ to the $\\mathbf{x}$ values before calculating the dot product (adjusting the dimension of $\\mathbf{w}$ accordingly)?\n",
        "\n",
        "In this case the decision function becomes:\n",
        "\n",
        "$$\n",
        "y = \\begin{cases}\n",
        "\t1 & \\text{if $\\mathbf{w}\\cdot f(\\mathbf{x}) \\ge 0$}\\\\\n",
        "\t0 & \\text{otherwise}\n",
        "     \\end{cases}\n",
        "$$\n",
        "\n",
        "What might be some interesting functions to use as $f$? Try implementing them for $d=2$ and see what boundaries you can construct."
      ],
      "metadata": {
        "id": "G3jDhq5-CrrB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Construct decision boundaries by using a different functional form for *y*\n",
        "\n",
        "In the previous question, the preprocessing function $f$ does not involve the weights vector $\\mathbf{w}$. Rather than invoking such an extra function, we might instead use a modified decision function that uses the weights in a different way.\n",
        "\n",
        "For example, consider using a $(d + 1) \\times (d + 1)$ *matrix* of weights, $\\mathbf{W}$, rather than just a vector, and adapting the decision function like this:\n",
        "\n",
        "$$\n",
        "y = \\begin{cases}\n",
        "\t1 & \\text{if $\\mathbf{x}^\\mathsf{T}\\mathbf{Wx} \\ge 0$}\\\\\n",
        "\t0 & \\text{otherwise}\n",
        "     \\end{cases}\n",
        "$$\n",
        "\n",
        "What kinds of decision boundaries might this enable? Can you suggest any conditions under which this decision function is or is not useful? Again, try implementing this for $d=2$ and see what you get.\n"
      ],
      "metadata": {
        "id": "QdszRbRICx_t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Construct decision boundaries iteratively or recursively\n",
        "\n",
        "As another alternative, we might choose not restrict ourselves to a single set of weights but instead have multiple distinct weight vectors, $\\mathbf{w}_1, \\mathbf{w}_2, ... \\mathbf{w}_k$. Each of these would define a linear boundary, just as in Task 2, but what might that mean collectively?\n",
        "\n",
        "Suppose we define our decision function as\n",
        "\n",
        "$$\n",
        "y = \\sum_i^k \\mathbb{1}(\\mathbf{w}_i \\cdot \\mathbf{x} \\ge 0)\n",
        "$$\n",
        "\n",
        "where $\\mathbb{1}$ is the **indicator function**:\n",
        "\n",
        "$$\n",
        "\\mathbb{1}(cond) = \\begin{cases}\n",
        "\t1 & \\text{if } cond \\text{ is true}\\\\\n",
        "\t0 & \\text{otherwise}\n",
        "     \\end{cases}\n",
        "$$\n",
        "\n",
        "What kind of value is $y$? What kinds of decision boundaries might result?\n",
        "\n",
        "Suppose instead we have $k=3$ and define our decision function as\n",
        "\n",
        "$$\n",
        "y = \\begin{cases}\n",
        "\t\\mathbb{1}(\\mathbf{w}_2 \\cdot \\mathbf{x} \\ge 0) & \\text{if } \\mathbf{w}_1\\cdot \\mathbf{x} \\ge 0\\\\\n",
        "\t\\mathbb{1}(\\mathbf{w}_3 \\cdot \\mathbf{x} \\ge 0)  & \\text{otherwise}\n",
        "     \\end{cases}\n",
        "$$\n",
        "\n",
        "What sort of decision boundaries could we define like this? What if we allowed $k$ to be much larger?\n",
        "\n",
        "Again, try implementing some of these for $d=2$ and see what you can come up with.\n"
      ],
      "metadata": {
        "id": "ukIuuS_9C6Q1"
      }
    }
  ]
}